{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter notebook illustrating  commands required to use Python 2.7 modules\n",
    "\n",
    "Copyright 2016 Ursa Analytics, Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell below loads the required modules and packages.  Code provided places all custom files in ./src.  3rd party dependencies assumed to be installed on system (Dockerfile provided illustratres one working computational environment).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load custom files provided with this repo under the Apache 2 license.\n",
    "import MotBnB_Batch as MotionBlurFilter\n",
    "import MotBnBwithNDClassKF_Batch\n",
    "import findBerglundVersionOfMA1_Batch #this module builds off of Berglund's 2010 PRE parameterization (atypical MA1 formulation)\n",
    "\n",
    "# imports below load standard 3rd party packages\n",
    "%matplotlib inline \n",
    "#command above avoids using the pylab flag when launching ipython (always put magic command above as first arg to ipynb file)\n",
    "\n",
    "#load some standard scientific computing and plotting modules (code tested using Python 2.7.10, Scipy 0.15.1, and Matplotlib 1.4.3)\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy.optimize as spo\n",
    "import matplotlib.font_manager as font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "####################################\n",
    "\n",
    "\n",
    "def loadh5(floc,dsetnameIndex=0,printFile=False,printDsets=False): #load a numeric hdf5 file. \"floc\" is the path of ASCII file to read.\n",
    "    \"\"\"\n",
    "    loadh5(floc,dsetnameIndex=0,printFile=False,printDsets=False): #load a numeric hdf5 file. \"floc\" is the path of ASCII file to read.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if floc[0]=='~':  #replace standard unix home shortcut with explicit path\n",
    "        floc='/Users/calderoc' + floc[1:]\n",
    "    f=h5py.File(floc,'r')\n",
    "    dsetNames = f.keys()\n",
    "    if printFile:\n",
    "        print 'Read file: ' + floc\n",
    "        print 'Pulling Dataset index', dsetnameIndex, 'Named: ' + dsetNames[ix]\n",
    "    if printDsets:\n",
    "        if printFile:\n",
    "            print 'Displaying top level dsets in hdf5 file since printDset set to True'\n",
    "            print 'Found N= ',len(f.keys()),'top level dsets (returning integer vs. any data since printDset=True)'\n",
    "            for i in f.keys():\n",
    "                print i\n",
    "        return len(f.keys())\n",
    "    else:\n",
    "        dsetname=dsetNames[dsetnameIndex]\n",
    "        g= f[dsetname]  #default name for h5import dataset when no arg given (so i use this in my scripts as well)\n",
    "        g= np.array(g) #return numpy array (get shape with g.shape)\n",
    "        f.close()\n",
    "    return g \n",
    "\n",
    "def loadh5retdsetname(floc,dsetnameIndex=0,printFile=False,printDsets=False): #load a numeric hdf5 file. \"floc\" is the path of ASCII file to read.\n",
    "    \"\"\"\n",
    "    loadh5retdsetname(floc,dsetnameIndex=0,printFile=False,printDsets=False): #load a numeric hdf5 file. \"floc\" is the path of ASCII file to read.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if floc[0]=='~':  #replace standard unix home shortcut with explicit path\n",
    "        floc='/Users/calderoc' + floc[1:]\n",
    "    f=h5py.File(floc,'r')\n",
    "    dsetNames = f.keys()\n",
    "    dsetname=dsetNames[0] #default to returning first name in list\n",
    "    if printFile:\n",
    "        print 'Read file: ' + floc\n",
    "        print 'Pulling Dataset index', dsetnameIndex, 'Named: ' + dsetNames[ix]\n",
    "    if printDsets:\n",
    "        if printFile:\n",
    "            print 'Displaying top level dsets in hdf5 file since printDset set to True'\n",
    "            print 'Found N= ',len(f.keys()),'top level dsets (returning integer vs. any data since printDset=True)'\n",
    "            for i in f.keys():\n",
    "                print i\n",
    "        return len(f.keys())\n",
    "    else:\n",
    "        dsetname=dsetNames[dsetnameIndex]\n",
    "        g= f[dsetname]  #default name for h5import dataset when no arg given (so i use this in my scripts as well)\n",
    "        g= np.array(g) #return numpy array (get shape with g.shape)\n",
    "        f.close()\n",
    "    return g,dsetname\n",
    "\n",
    "\n",
    "def wouth5(floc,DATAMAT,dset='dataset0'): #write a simple hdf5 file into \"floc\";  assumes numpy array passed as DATAMAT.  handling other datatypes with h5py is fairly easy\n",
    "    \"\"\"\n",
    "    def wouth5(floc,DATAMAT,dset='dataset0')\n",
    "    write an hdf5 file dumping everything into generic name useful for playing with other programs \"/dataset0.\"  \n",
    "\n",
    "    floc: file location  (can use \"~\" in path) \n",
    "    DATAMAT: numpy matrix or vector\n",
    "\n",
    "    \"\"\"\n",
    "    if floc[0]=='~':  #replace standard unix home shortcut with explicit path\n",
    "                floc='/Users/calderoc' + floc[1:] #purdue login: calderoc / princeton: ccaldero; since grad school i use either calderoc or ccalderoN as unix logins (keep symlink to both home folders in *nix style systems)\n",
    "    f=h5py.File(floc,'a')#default name for h5import dataset when no arg given (so i use this in my scripts as well)\n",
    "    dset = f.create_dataset(dset, data=DATAMAT)\n",
    "    f.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Now that required modules packages are loaded, set parameters for simulating \"Blurred\" OU trajectories.  Specific mixed continuous/discrete model:\n",
    "\n",
    "\\begin{align}\n",
    "dr_t = & ({v}-{\\kappa} r_t)dt + \\sqrt{2 D}dB_t \\\\\n",
    "\\psi_{t_i} = & \\frac{1}{t_E}\\int_{t_{i}-t_E}^{t_i} r_s ds + \\epsilon^{\\mathrm{loc}}_{t_i}\n",
    "\\end{align}\n",
    "\n",
    "###In above equations, parameter vector specifying model is: $\\theta = (\\kappa,D,\\sigma_{\\mathrm{loc}},v)$\n",
    "\n",
    "\n",
    "###Statistically exact discretization of above for uniform time spacing  $\\delta$  (non-uniform $\\delta$ requires time dependent vectors and matrices below):\n",
    "\n",
    "\\begin{align}\n",
    "r_{t_{i+1}} = & A + F r_{t_{i}} + \\eta_{t_i} \\\\\n",
    "\\psi_{t_i} = & H_A + H_Fr_{t_{i-1}} + \\epsilon^{\\mathrm{loc}}_{t_i} + \\epsilon^{\\mathrm{blur}}_{t_i} \\\\\n",
    "\\epsilon^{\\mathrm{loc}}_{t_i} + & \\epsilon^{\\mathrm{blur}}_{t_i} \\sim  \\mathcal{N}(0,R_i) \\\\\n",
    "\\eta_i \\sim & \\mathcal{N}(0,Q) \\\\\n",
    "t_{i-1} \\le & t_{i}-t_E \\\\\n",
    " C = & cov(\\epsilon^{\\mathrm{blur}}_{t_i},\\eta_{t_{i-1}}) \\ne 0\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "####Notes:  \n",
    "##### 1) Kalman Filter (KF) and Motion Blur Filter (MBF) codes estimate $\\sqrt{(2D)}$  as \"thermal noise\" parameter.  \n",
    "##### 2) The expression $ t_{i-1} \\le & t_{i}-t_E $ shows that non-uniform time spacing is possible.  Code provided can efficientle handle cases where \"time lapse\" is intentionally used (e.g. laser is on periodically) or in \"blinking cases\" (e.g. continuous illumination used, but fluor enters dark state causing particle to be missed in some frames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set parameters determining state dynamics.  everything in this block can by changed in batch.  \n",
    "# keep derived quantities in cell below read in.\n",
    "# kappa = 1. # units: [1/s] %code currently setup to set kappa to achieve desired \"corral radius\" defined by L.\n",
    "v = 0. #units [microns/s]\n",
    "D = 1. #units [microns^2/s] %use this to show convergence\n",
    "L= 500/1000. #[radius or box width in microns]\n",
    "#parmeters determining trajectory length, uniform spacing in time, and number of trajectories to analyze \n",
    "offset=0. #if no localization accuracy info, probably not a bad idea to have zero offset and put in a high constant initial guess for noise\n",
    "locIG = 40./1000.\n",
    "\n",
    "ds=1 #\"down sampling\" integer parameter.  \n",
    "delta = 10./1000. #spacing between \"image observations\" under \"continuous illumination\" sampling\n",
    "#for time lapse model used, assumes time between two image frames is ds*delta.  code can be modified to handle \"more exotic\" situations\n",
    "exposureTime=delta #this is a fixed experimental control parameter.  set input parameter needed \n",
    "#(exposureTime=delta may look redudant based on comment, but aux varialbe is used to identify \"gaps\" induced by blinking)\n",
    "deltaNET = exposureTime*ds #define as net time of frame (not exposure time) for time lapse tests.  \n",
    "#Heuristic: if t_E/deltaNET is small, MBF correction will be small (e.g. analyzing as standard KF will likely introduce little approximation error)  \n",
    "#for non-uniform time spacing, need to specify a time vector (code illustrates how to set this up)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target L [nm]:  500.0\n",
      "kappa yielding target for given D 48.0\n",
      "D/kappa true: 0.0208333333333\n",
      "L^2/6 0.0416666666667\n",
      "baseline pars (-2, 0, 0, -2, 1.4142135623730951, 0, 1.4142135623730951, 0.03, 0.03, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "kappa = 2*D*6/(L**2)\n",
    "print 'target L [nm]: ', L*1000\n",
    "print 'kappa yielding target for given D',kappa\n",
    "\n",
    "twoDsqrt = np.sqrt(D*2.) #filter codes provided (KF and MBF) estimate square root of 2D directly.\n",
    "trueRatio = D/kappa\n",
    "print 'D/kappa true:',trueRatio\n",
    "print 'L^2/6',L**2/6.\n",
    "\n",
    "\n",
    "\n",
    "pars=(-2,0,0,-2,twoDsqrt,0,twoDsqrt, 30./1000.,30./1000.,0,0)\n",
    "print 'baseline pars',pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./cp2019_401/cp2019_401.h5'] 1\n"
     ]
    }
   ],
   "source": [
    "import glob2\n",
    "\n",
    "datadir='./cp2019_401/**/*.h5'\n",
    "\n",
    "# datadir='./ManualEGs/**/*.h5' # These are the control cells, \n",
    "\n",
    "\n",
    "\n",
    "# datadir='TA (Sec61)/**/*.csv' # These are cells pharmacologically treated that should slow down luminal motion (at least at the ensemble level as demonstrated by FRAP)\n",
    "srcFiles = glob2.glob(datadir)\n",
    "#with this approach, output cannot exist, but h5py and formulation crashes if files exists when trying to duplicate dataset, so just be sure to move or erase output files\n",
    "#containint \"_BlurRes\",\"_KFRes\",etc\n",
    "# print srcFiles[0]\n",
    "print srcFiles,len(srcFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1054 trajectories in  ./cp2019_401/cp2019_401.h5\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Batch  1  of  1054 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "\n",
      "Demeaning data:\n",
      "Classic 2D KF results:  final_simplex: (array([[-5.40080087e+00, -7.32892657e-01,  1.32459652e-01,\n",
      "        -2.56200396e-01,  1.56073728e+00, -2.08408394e-01,\n",
      "         1.82600185e+00,  3.89522165e-02,  4.22167065e-03,\n",
      "        -1.04375986e-01,  2.49609095e-01],\n",
      "       [-5.33321416e+00, -7.19841970e-01,  1.29993644e-01,\n",
      "        -2.52490722e-01,  1.57234246e+00, -2.04800939e-01,\n",
      "         1.83066118e+00,  3.74858323e-02,  5.88070543e-03,\n",
      "        -1.02404615e-01,  2.45282601e-01],\n",
      "       [-5.41428657e+00, -7.39876785e-01,  1.33701914e-01,\n",
      "        -2.58379492e-01,  1.57596505e+00, -2.10421600e-01,\n",
      "         1.82020502e+00,  3.82145692e-02,  4.27308350e-03,\n",
      "        -1.05441074e-01,  2.52003016e-01],\n",
      "       [-5.48750910e+00, -7.41810151e-01,  1.33985225e-01,\n",
      "        -2.59977445e-01,  1.56102919e+00, -2.11052132e-01,\n",
      "         1.81922921e+00,  3.87212375e-02,  6.17855361e-03,\n",
      "        -1.05810671e-01,  2.52516182e-01],\n",
      "       [-5.17567983e+00, -7.33577972e-01,  1.32598398e-01,\n",
      "        -2.56592997e-01,  1.55841671e+00, -2.08610194e-01,\n",
      "         1.81939205e+00,  3.84882408e-02,  4.46657837e-03,\n",
      "        -1.04463246e-01,  2.49986355e-01],\n",
      "       [-5.31557091e+00, -7.45788531e-01,  1.34800190e-01,\n",
      "        -2.58998040e-01,  1.56033603e+00, -2.12104794e-01,\n",
      "         1.81106283e+00,  3.89704686e-02,  5.09177440e-03,\n",
      "        -1.06379017e-01,  2.53954775e-01],\n",
      "       [-5.32326496e+00, -7.30879398e-01,  1.32156734e-01,\n",
      "        -2.56214814e-01,  1.56525462e+00, -2.07784087e-01,\n",
      "         1.82154186e+00,  3.90373848e-02,  3.61493761e-03,\n",
      "        -1.04056551e-01,  2.48956887e-01],\n",
      "       [-5.37584368e+00, -7.39879929e-01,  1.33611435e-01,\n",
      "        -2.57966349e-01,  1.56242207e+00, -2.10544885e-01,\n",
      "         1.81821072e+00,  3.81811276e-02,  6.98226711e-03,\n",
      "        -1.05524746e-01,  2.51930420e-01],\n",
      "       [-5.41673770e+00, -7.43556032e-01,  1.34391975e-01,\n",
      "        -2.60332495e-01,  1.55480928e+00, -2.11477259e-01,\n",
      "         1.80974149e+00,  3.96209084e-02,  5.78354034e-03,\n",
      "        -1.06088233e-01,  2.53052681e-01],\n",
      "       [-5.53891327e+00, -7.66934414e-01,  1.38494282e-01,\n",
      "        -2.68156883e-01,  1.57052631e+00, -2.18232894e-01,\n",
      "         1.82067490e+00,  3.78514111e-02,  4.97873945e-03,\n",
      "        -1.09586531e-01,  2.61150998e-01],\n",
      "       [-5.46751465e+00, -7.26527317e-01,  1.31320515e-01,\n",
      "        -2.55390984e-01,  1.56726430e+00, -2.06607572e-01,\n",
      "         1.81006110e+00,  3.94821665e-02,  5.94207969e-03,\n",
      "        -1.03506660e-01,  2.47226150e-01],\n",
      "       [-5.61855564e+00, -7.73377323e-01,  1.39719163e-01,\n",
      "        -2.70231098e-01,  1.55973795e+00, -2.19989544e-01,\n",
      "         1.82593872e+00,  3.88100134e-02,  3.34369995e-03,\n",
      "        -1.10529671e-01,  2.63305319e-01]]), array([-0.72418595, -0.72412714, -0.72411445, -0.72407449, -0.72405445,\n",
      "       -0.72403607, -0.72401491, -0.72400779, -0.72399357, -0.72398125,\n",
      "       -0.72397402, -0.7239493 ]))\n",
      "           fun: -0.7241859517657727\n",
      "       message: 'Maximum number of function evaluations has been exceeded.'\n",
      "          nfev: 2200\n",
      "           nit: 1584\n",
      "        status: 1\n",
      "       success: False\n",
      "             x: array([-5.40080087e+00, -7.32892657e-01,  1.32459652e-01, -2.56200396e-01,\n",
      "        1.56073728e+00, -2.08408394e-01,  1.82600185e+00,  3.89522165e-02,\n",
      "        4.22167065e-03, -1.04375986e-01,  2.49609095e-01])\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Batch  2  of  1054 &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "\n",
      "Demeaning data:\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) #set seed to allow reproducible data.  \n",
    "myoptmeth='nelder-mead' #set optimization for MLE search (recommended to use nelder-mead due to highly nonlinear nature of MLE)\n",
    "\n",
    "\n",
    "pltFlag = False\n",
    "\n",
    "for fname in srcFiles :\n",
    "# for fname in srcFiles[0:1]: #test case (don't just give single values since strings are iterable...)\n",
    "    Nbatch = loadh5retdsetname(fname,printDsets=True)\n",
    "    print 'Found',Nbatch, 'trajectories in ',fname\n",
    "    \n",
    "    #inset code specific read here.  make a routine for pulling batches\n",
    "    for ni in range(Nbatch):\n",
    "#     for ni in range(2):\n",
    "        \n",
    "        batchY = [] #reset data passed to arg.  if desired to save, simple mod (probably best to just set random number seed)\n",
    "        batchNoiseMag = []\n",
    "        batchTdata = []\n",
    "        print '\\n','^'*100 \n",
    "        print 'Batch ', ni + 1 , ' of ', Nbatch, '&'*50\n",
    "        print '^'*100 ,'\\n\\n'\n",
    "        \n",
    "        data,dsetname = loadh5retdsetname(fname,dsetnameIndex=ni)\n",
    "        batchTdata = [data[:,1]] #need lists as input\n",
    "        batchXYdata = data[:,2:4] #added meta info in form of dz to last column.  be explicit with frame,time,x,y,z\n",
    "        \n",
    "        \n",
    "        if pltFlag:\n",
    "            print fname\n",
    "            plt.plot(batchXYdata[0,:],batchXYdata[1,:],'-o')\n",
    "            plt.show()\n",
    "            plt.plot(batchXYdata[0,:],'->')\n",
    "            plt.plot(batchXYdata[1,:],'-x')\n",
    "            plt.show()\n",
    "        \n",
    "        #setup some lists to store results o single trajectory in file \n",
    "        res1=[];res2=[];res3=[];res1b=[];res2Bias=[];res3Bias=[];\n",
    "        \n",
    "#         for traji in batchXYdata:\n",
    "        for fauxvar in range(1):\n",
    "            \n",
    "            traji = batchXYdata\n",
    "            print 'Demeaning data:'\n",
    "            traji = traji - np.mean(traji,axis=0)\n",
    "            \n",
    "            batchY=[traji]\n",
    "        \n",
    "        #     BlurF = MotionBlurFilter.ModifiedKalmanFilter1DwithCrossCorr(batchY,batchTdata,StaticErrorEstSeq= batchNoiseMag)\n",
    "#             batchNoiseMag = [np.ones(batchTdata[0].shape)*locIG]\n",
    "#             BlurF = MotionBlurFilter.ModifiedKalmanFilter1DTimeLapse(batchY,batchTdata,exposureTime,StaticErrorEstSeq= batchNoiseMag)\n",
    "            KF = MotBnBwithNDClassKF_Batch.KalmanFilterND(batchY,batchTdata)\n",
    "            \n",
    "#             MA = findBerglundVersionOfMA1_Batch.CostFuncMA1Diff_Batch(batchY,deltaNET,blurCoef=1./6.)\n",
    "#             MAb = findBerglundVersionOfMA1_Batch.CostFuncMA1Diff_Batch(batchY,deltaNET,blurCoef=0)\n",
    "        #     BlurF = MotionBlurFilter.ModifiedKalmanFilter1DTimeLapse(batchY,batchTdata,exposureTime)\n",
    "#             KF = MotionBlurFilter.ClassicKalmanFilter(batchY,batchTdata)\n",
    "        #     MA = findBerglundVersionOfMA1_Batch.CostFuncMA1Diff_Batch(batchY,deltaNET,blurCoef=1./6.)\n",
    "        #     MAb = findBerglundVersionOfMA1_Batch.CostFuncMA1Diff_Batch(batchY,deltaNET,blurCoef=0)\n",
    "            \n",
    "            parsIG = [3.*i/4. for i in pars] #kick off simulations with a biased estimate of truth (for long trajectories IC, less relevant, but for small sample sizes, need reasonable IC since local minima can be problematics)\n",
    "            \n",
    "        #repeat optimization to ensure minimal IG dependence (important for short traj)\n",
    "            Nrepeat = 3\n",
    "            maxHist = [np.inf,np.inf,np.inf,np.inf] #set inf as initial value\n",
    "            maxRes= [[],[],[],[]] #give bogus IGs\n",
    "            \n",
    "            for nrpt in range(Nrepeat):\n",
    "                parsIG = [i+i*.2*np.random.normal(1) for i in pars]\n",
    "                \n",
    "#                 resMAtmp = spo.minimize(MA.evalCostFuncVel_Batch,[parsIG[1]/np.sqrt(2),parsIG[2],parsIG[-1]], method=myoptmeth)\n",
    "#                 resMAbtmp = spo.minimize(MAb.evalCostFuncVel_Batch,[parsIG[1]/np.sqrt(2),parsIG[2],parsIG[-1]], method=myoptmeth)\n",
    "#                 resBlurtmp = spo.minimize(BlurF.evalCostFunc,parsIG, method=myoptmeth)            \n",
    "                resKFtmp = spo.minimize(KF.evalCostFunc,parsIG, method=myoptmeth)\n",
    "                resBlurtmp=resKFtmp;resMAtmp=resKFtmp;resMAbtmp=resKFtmp #use place holders to avoid making changes below\n",
    "                #store the optimization output structure\n",
    "                tmpVec = [resMAtmp,resMAbtmp,resBlurtmp,resKFtmp]\n",
    "                \n",
    "                #cycle through and update based on max vals obtained\n",
    "                for ix,resi in enumerate(tmpVec):\n",
    "                    fval = resi.fun\n",
    "                    if fval<maxHist[ix]:\n",
    "                        maxRes[ix]=resi\n",
    "                        maxHist[ix]=fval\n",
    "                        \n",
    "\n",
    "                resKF=maxRes[3]\n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "            print 'Classic 2D KF results:',resKF\n",
    "            print '$'*100\n",
    "            res3.append(resKF.x)\n",
    "\n",
    "    \n",
    "        #store results in hdf5 file\n",
    "        fbase = fname[:-3]\n",
    "#         wouth5(fbase+'_MARes'+'.h5',res1,dset=dsetname)\n",
    "#         wouth5(fbase+'_MAResBlurCoefRes'+'.h5' ,res1b,dset=dsetname)\n",
    "#         wouth5(fbase+'_BlurRes'+'.h5' ,res2,dset=dsetname)\n",
    "        wouth5(fbase+'_KF2DRes'+'.h5',res3,dset=dsetname)\n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
